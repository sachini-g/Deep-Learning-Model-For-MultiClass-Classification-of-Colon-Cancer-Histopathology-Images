# -*- coding: utf-8 -*-
"""Vortex_Notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ksjG7YypYCTWP4JJDX7zhwSqXwd_uthP

# Problem Definition
### **Clinical and Healthcare Relevance**

Colorectal cancer is one of the most prevalent and life-threatening cancers worldwide, ranking among the top causes of cancer-related mortality in both men and women. Early detection and accurate classification of colorectal lesions are critical for improving patient prognosis, treatment planning, and survival rates.

Histopathological examination of colorectal tissue biopsies stained with Hematoxylin and Eosin (H&E) is considered the gold standard for colorectal cancer diagnosis. However, manual interpretation of histopathology slides is:

* Time-consuming

* Subject to inter-observer variability

* Highly dependent on expert pathologists

With increasing biopsy volumes, there is a growing need for computer-aided diagnostic (CAD) systems that can assist pathologists by providing accurate, consistent, and reproducible assessments.

Deep learning–based image classification models can learn complex tissue patterns and morphological features directly from histopathology images, making them suitable for supporting colorectal cancer diagnosis and grading.

### **What Is Being Predicted?**

In this project, we address a multi-class image classification problem using histopathological images of colorectal tissue.

The model predicts one of six colorectal tissue categories for each input histopathology image:

1. Normal

2. Polyp

3. Low-grade intraepithelial neoplasia

4. High-grade intraepithelial neoplasia

5. Serrated adenoma

6. Adenocarcinoma

Each input image is classified based on the **most prominent and severe histological differentiation stage** present in the tissue section.

The objective is to train a deep learning model that can automatically distinguish between normal tissue, precancerous lesions, and malignant colorectal cancer, thereby supporting early diagnosis and clinical decision-making.

# Dataset Documentation
### **Dataset Overview**

This study uses the EBHI-Seg (Enteroscope Biopsy Histopathological H&E Image Dataset), a publicly available medical imaging dataset designed for colorectal cancer analysis.

The dataset contains histopathological images of colorectal tissue sections stained with Hematoxylin and Eosin (H&E), captured from intestinal biopsy samples under high magnification.

Although the dataset was originally introduced for image segmentation tasks, in this project it is utilized for multi-class histopathological image classification.

### **Dataset Citation**

A. Babaei, “EBHI-Dataset,” Kaggle.com, 2025. https://www.kaggle.com/datasets/alibabaei78/ebhi-seg (accessed Jan. 03, 2026).

### **Data Source and Acquisition Details**

* Tissue source: Intestinal biopsy specimens (colon and rectum)
* Imaging modality: Light microscopy
* Staining technique: Hematoxylin and Eosin (H&E)
* Microscope: Nissan Olympus microscope
* Acquisition software: NewUsbCamera
* Magnification:
    * Eyepiece: 10×
    * Objective lens: 40×
    * Effective magnification: 400×
* Image resolution: 224 × 224 pixels
* File format: PNG

The dataset was annotated by two experienced histopathologists and curated by 12 biomedical researchers following strict labeling guidelines.

If multiple differentiation stages were present in an image, the most prominent and severe stage was assigned as the label.

### **Variables and Label Description**

**Input Variable:**
* RGB histopathology image of size 224 × 224 × 3

**Target Variable (Class Label):**
One of the following six classes:

| Class |	Description |
|------|------|
| Normal |	Regular, well-organized tubular structures with no signs of abnormality |
| Polyp |	Redundant mucosal growth with altered histological structure but intact lumen |
| Low-Grade IN | Mild precancerous changes with increased gland branching and nuclear variation |
| High-Grade IN |	Severe precancerous lesions with marked structural distortion and nuclear enlargement |
| Serrated Adenoma | Rare lesions with serrated glandular architecture |
| Adenocarcinoma | Malignant tumor with irregular gland distribution and poorly defined boundaries |

### **Data Distribution and Class Imbalance**

The dataset consists of 4,456 images, including:
* 2,228 original histopathology images
* 2,228 corresponding ground-truth segmentation masks

For the classification task, only the histopathology images are used.

Class distribution of histopathology images:

| Class |	Number of Images |
|------|------|
| Normal |	76 |
| Polyp |	474 |
| Low-Grade IN |	639 |
| High-Grade IN |	186 |
| Serrated Adenoma |	58 |
| Adenocarcinoma |	795 |

This distribution shows a significant class imbalance, particularly for:
* Normal tissue
* Serrated adenoma

This imbalance motivates the use of data augmentation and appropriate evaluation metrics during model training.
"""

# Install the Kaggle API to allow programmatic dataset downloads
!pip install kaggle

# Kaggle API Authentication
# To download the dataset securely, Kaggle API credentials are configured.
# This ensures authenticated and reproducible access to the EBHI-Seg dataset.

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Download the EBHI-Seg histopathological image dataset from Kaggle
# This dataset contains H&E-stained colorectal tissue images

!kaggle datasets download -d alibabaei78/ebhi-seg

# Extract the downloaded dataset archive
# The dataset is provided as a compressed ZIP file

from zipfile import ZipFile
dataset = '/content/ebhi-seg.zip'

with ZipFile(dataset,'r') as zip:
  zip.extractall()
  print('The dataset is extracted')

# Import essential libraries for file handling and image processing

import os              # For directory and file operations
import cv2             # OpenCV for image reading and processing
import numpy as np     # Numerical operations on image arrays

"""#### Dataset Structure and Class Organization

The EBHI-Seg dataset is organized into separate folders for each histopathological class.
Each folder contains image files corresponding to a specific colorectal tissue category.

In this step, image filenames are listed for each class to enable dataset exploration and class distribution analysis.

"""

# List image files for each histopathological class
# This helps in understanding dataset structure and class-wise image counts

images_adenocarcinoma = os.listdir('/content/EBHI-SEG/Adenocarcinoma/image')
images_highgradein = os.listdir('/content/EBHI-SEG/High-grade IN/image')
images_lowgradein = os.listdir('/content/EBHI-SEG/Low-grade IN/image')
images_normal = os.listdir('/content/EBHI-SEG/Normal/image')
images_polyp = os.listdir('/content/EBHI-SEG/Polyp/image')
images_serratedadenoma = os.listdir('/content/EBHI-SEG/Serrated adenoma/image')

# Display the first five image filenames from the Adenocarcinoma class
print(images_adenocarcinoma[0:5])

# Display the total number of images in the Adenocarcinoma class
print(len(images_adenocarcinoma))

"""#### Visual Inspection of Histopathology Images

A representative sample image is displayed to visually examine the histopathological patterns,
image quality, and staining characteristics before model training.

"""

# Display a sample histopathology image from the Adenocarcinoma class
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

img = mpimg.imread('/content/EBHI-SEG/Adenocarcinoma/image/GT2001837-1-400-001.png')
plt.imshow(img)
plt.axis('off')
plt.show()

"""### Image Loading and Standardization

In this step, histopathology images are loaded and converted into numerical arrays suitable for deep learning models.

Basic standardization operations are applied to ensure consistent image dimensions and color channels.
Detailed preprocessing steps are documented in a later section.
"""

# Convert histopathology images into NumPy arrays for model input
# Images are resized and converted to RGB format for consistency

from PIL import Image

def load_and_process_images(image_paths, folder_path):
    images_array = []
    for img_file in image_paths:
        # Open image file
        image = Image.open(folder_path + img_file)
        # Resize image to match EfficientNet-B0 input size
        image = image.resize((224, 224))
        # Convert image to RGB format
        image = image.convert('RGB')
        # Convert image to NumPy array and store
        images_array.append(np.array(image))
    return images_array

# Load and process images for each class
adenocarcinoma_images_array_list = load_and_process_images(
    images_adenocarcinoma, '/content/EBHI-SEG/Adenocarcinoma/image/')
highgradein_images_array_list = load_and_process_images(
    images_highgradein, '/content/EBHI-SEG/High-grade IN/image/')
lowgradein_images_array_list = load_and_process_images(
    images_lowgradein, '/content/EBHI-SEG/Low-grade IN/image/')
normal_images_array_list = load_and_process_images(
    images_normal, '/content/EBHI-SEG/Normal/image/')
polyp_images_array_list = load_and_process_images(
    images_polyp, '/content/EBHI-SEG/Polyp/image/')
sadenoma_images_array_list = load_and_process_images(
    images_serratedadenoma, '/content/EBHI-SEG/Serrated adenoma/image/')

"""#### Verification of Processed Image Data

After loading and standardizing the images, sample outputs from each class are visualized.
This step verifies that resizing, RGB conversion, and array transformation were performed correctly
and that the image content is preserved.

"""

# Display a processed Adenocarcinoma image as a NumPy array

print(adenocarcinoma_images_array_list[0])

img_array = adenocarcinoma_images_array_list[0]

plt.imshow(img_array)
plt.axis('off')
plt.show()

# Display a processed High-grade Intraepithelial Neoplasia image

print(highgradein_images_array_list[0])

img_array = highgradein_images_array_list[0]

plt.imshow(img_array)
plt.axis('off')
plt.show()

# Display a processed Low-grade Intraepithelial Neoplasia image

print(lowgradein_images_array_list[0])

img_array = lowgradein_images_array_list[0]

plt.imshow(img_array)
plt.axis('off')
plt.show()

# Display a processed Normal colorectal tissue image

print(normal_images_array_list[0])

img_array = normal_images_array_list[0]

plt.imshow(img_array)
plt.axis('off')
plt.show()

# Display a processed Polyp image

print(polyp_images_array_list[0])

img_array = polyp_images_array_list[0]

plt.imshow(img_array)
plt.axis('off')
plt.show()

# Display a processed Serrated Adenoma image

print(sadenoma_images_array_list[0])

img_array = sadenoma_images_array_list[0]

plt.imshow(img_array)
plt.axis('off')
plt.show()

"""### Dataset Assembly and Label Encoding

After image loading and standardization, all images are combined into a single dataset.
Each image is assigned a numerical class label corresponding to its histopathological category.

This step prepares the data for model training and evaluation.
"""

# Combine images from all classes into a single dataset
# Assign numerical labels to each class for multi-class classification

X = []  # List to store image data
y = []  # List to store corresponding class labels

for label, class_list in enumerate([
   adenocarcinoma_images_array_list,
    highgradein_images_array_list,
    lowgradein_images_array_list,
    normal_images_array_list,
    polyp_images_array_list,
    sadenoma_images_array_list
]):
    print(f"Processing class label: {label}")
    for img in class_list:
        X.append(img)     # Append image data
        y.append(label)   # Append corresponding label

# Verify that the number of images and labels match

print(len(X))
print(len(y))

"""### Train, Validation, and Test Split Strategy

To ensure realistic and unbiased evaluation, the dataset is divided into three mutually exclusive subsets:
- Training set
- Validation set
- Test set

Stratified splitting is used to preserve class distribution across all subsets.
"""

# Split the dataset into training and temporary sets
# 70% of data is used for training, while 30% is reserved for validation and testing

from sklearn.model_selection import train_test_split

# 70% train, 30% temp
X_train, X_temp, y_train, y_temp = train_test_split(
    X, y,
    test_size=0.3,
    stratify=y,       # Preserve class distribution
    random_state=42   # Ensure reproducibility
)

# Split the temporary set equally into validation and test sets
# Each represents 15% of the total dataset

X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp,
    test_size=0.5,    # 50% of 30% → 15%
    stratify=y_temp,  # Maintain class balance
    random_state=42
)

# Display the number of samples in each dataset split

print(len(X_train))
print(len(X_val))
print(len(X_test))

# Analyze class distribution in the training set

from collections import Counter

class_counts = Counter(y_train)
print(class_counts)

"""## Data Augmentation Strategy
Due to significant class imbalance in the EBHI-SEG dataset, data augmentation is applied **only on the training set** to synthetically increase samples of minority classes.

Albumentations is used because it is a medically trusted library that preserves spatial integrity of histopathology images.

The goal is to:
- Reduce model bias toward majority classes
- Improve generalization
- Avoid overfitting to dominant tissue patterns

"""

import albumentations as A

# Define augmentation pipeline for training images only
augment = A.Compose([
    A.HorizontalFlip(p=0.5),                      # Simulates tissue orientation variations
    A.Rotate(limit=10, p=0.3),                    # Small rotations to avoid structural distortion
    A.RandomBrightnessContrast(0.1, 0.1, p=0.3)   # Handles staining and illumination differences
])

"""## Converting Training Data to NumPy Arrays
TensorFlow models require NumPy array inputs.
Here, the training images and labels are converted into NumPy format for efficient batch processing and augmentation.

"""

# Convert training images to NumPy array
# Shape: (number_of_samples, height, width, channels)
X_train_np = np.array([np.array(img) for img in X_train])

# Convert training labels to NumPy array
# Shape: (number_of_samples,)
y_train_np = np.array(y_train)

"""## Class-Balanced Augmentation
The dataset contains severe class imbalance.
To address this, a **class-wise augmentation strategy** is applied where each class is augmented until it reaches an equal number of samples.

This ensures:
- Balanced class representation
- Fair learning for minority cancer classes
- Improved recall for rare pathological patterns

"""

import random

# Lists to store augmented images and labels
X_aug, y_aug = [], []

# Original number of samples per class (before augmentation)
class_counts = {0: 556, 2: 446, 4: 332, 1: 130, 3: 53, 5: 41}

# Target: make all classes equal in size
target_counts = {
    0: 556,
    2: 556,
    4: 556,
    1: 556,
    3: 556,
    5: 556
}

# Perform class-wise augmentation
for cls, target in target_counts.items():
    cls_indices = np.where(y_train_np == cls)[0]
    # Extract images belonging to the class
    cls_images = X_train_np[cls_indices]

    # Add original images first (important to keep real data)
    X_aug.extend(cls_images)
    y_aug.extend([cls] * len(cls_images))

    # Number of synthetic images required
    num_to_generate = target - len(cls_images)

    # Generate augmented images if class is underrepresented
    if num_to_generate > 0:
        for _ in range(num_to_generate):
            img = cls_images[random.randint(0, len(cls_images) - 1)]
            augmented = augment(image=img)['image']
            X_aug.append(augmented)
            y_aug.append(cls)

# Convert augmented lists to NumPy arrays
X_aug = np.array(X_aug)
y_aug = np.array(y_aug)

# Check total number of augmented training samples
print(len(X_aug))
print(len(y_aug))

# Count samples per class after augmentation
counter_train = Counter(y_aug)
print(counter_train)

"""#### Shuffling Augmented Training Data
Shuffling prevents the model from learning class order bias during training.

"""

# Shuffle training data to randomize class order
from sklearn.utils import shuffle
X_aug, y_aug = shuffle(X_aug, y_aug, random_state=42)

# Convert shuffled augmented training data to NumPy arrays
X_aug_np = np.array([np.array(img) for img in X_aug])
y_aug_np = np.array(y_aug)

"""#### Validation and Test Data Preparation
Validation and test sets are **NOT augmented** to ensure unbiased performance evaluation.
Only conversion to NumPy arrays is performed.

"""

# Convert validation data to NumPy arrays
X_val_np = np.array([np.array(img) for img in X_val])  # shape: (num_val, 224, 224, 3)
y_val_np = np.array(y_val)  # shape: (num_val,)

# Convert test data to NumPy arrays
X_test_np = np.array([np.array(img) for img in X_test])  # shape: (num_val, 224, 224, 3)
y_test_np = np.array(y_test)  # shape: (num_val,)

"""### Image Preprocessing for EfficientNetB0
EfficientNet models require a specific input normalization.
The `preprocess_input` function scales pixel values to match the ImageNet training distribution.

"""

from tensorflow.keras.applications.efficientnet import preprocess_input

# Apply EfficientNet-specific preprocessing
X_aug_np = preprocess_input(X_aug_np)
X_val_np = preprocess_input(X_val_np)
X_test_np = preprocess_input(X_test_np)

# Display augmented training labels for verification
print(y_aug)

"""## Reproducibility and Experimental Control

To ensure reproducibility:
- Random seeds were fixed where applicable
- Deterministic data splitting was used
- All preprocessing and augmentation steps are explicitly shown
- Pretrained weights source is disclosed

"""

import random
import numpy as np
import tensorflow as tf

# Fix seeds for reproducibility
random.seed(42)
np.random.seed(42)
tf.random.set_seed(42)

"""## Model Initialization and Pretraining Disclosure
This project uses a pretrained deep learning model as the backbone for histopathology image classification.

### Pretrained Model Details
- **Model Name:** EfficientNetB0
- **Source:** Keras Applications (TensorFlow)
- **Original Training Dataset:** ImageNet
- **Original Task:** Generic natural image classification (1000 classes)

### Weight Initialization Strategy
- ✅ **Used pretrained weights**
- ❌ Did NOT train from scratch

The pretrained backbone is adapted to the medical imaging domain using transfer learning and fine-tuning.

"""

# Import TensorFlow and Keras libraries
import tensorflow as tf
from tensorflow import keras

# Import EfficientNetB0 architecture
from keras.applications import EfficientNetB0

# Initialize EfficientNetB0 as the backbone model
# weights='imagenet' → use pretrained ImageNet weights
# include_top=False → remove original classification head
# input_shape=(224,224,3) → required input size for EfficientNet

efficient_net = EfficientNetB0(
    weights='imagenet',
    include_top=False,
    input_shape=(224,224,3)
)

"""### Custom Loss Function: Sparse Categorical Focal Loss
Due to remaining difficulty in minority cancer classes, a **Focal Loss** is used instead of standard cross-entropy.

Focal Loss:
- Penalizes misclassified samples more heavily
- Focuses learning on hard-to-classify images
- Is well-suited for imbalanced medical datasets

"""

from tensorflow.keras import backend as K

# Custom implementation of Sparse Categorical Focal Loss
def sparse_categorical_focal_loss(alpha=0.25, gamma=2.0):
    def focal_loss(y_true, y_pred):
        # Convert sparse labels to one-hot encoding
        y_true = tf.one_hot(tf.cast(y_true, tf.int32), depth=6)
        # Clip predictions to avoid log(0) numerical instability
        y_pred = K.clip(y_pred, K.epsilon(), 1.0 - K.epsilon())

        # Compute standard categorical cross-entropy
        ce = -y_true * K.log(y_pred)
        # Apply focal loss scaling factor
        fl = alpha * K.pow(1 - y_pred, gamma) * ce

        # Sum loss over classes
        return K.sum(fl, axis=1)

    return focal_loss

"""## Model Architecture and Fine-Tuning Strategy
A transfer learning approach is used with EfficientNetB0 as a feature extractor and partial fine-tuning.

### Training Strategy
- Lower layers are frozen to preserve generic visual features
- Upper layers are unfrozen to adapt to histopathology-specific patterns
- Custom classification head is added for 6-class prediction

"""

# Freeze ALL layers of the pretrained EfficientNet backbone
for layer in efficient_net.layers:
  layer.trainable = False

# Unfreeze ONLY the last 20 layers
for layer in efficient_net.layers[-20:]:
    layer.trainable = True

# Build the full classification model
model = keras.Sequential([
    # Pretrained EfficientNet backbone
    efficient_net,
    # Reduce spatial dimensions
    keras.layers.GlobalAveragePooling2D(),
    # Normalize activations for stable training
    keras.layers.BatchNormalization(),

    # Fully connected layers for classification
    keras.layers.Dense(512, activation='relu'),
    keras.layers.Dropout(0.3),
    keras.layers.Dense(256, activation='relu'),
    keras.layers.Dropout(0.2),
    # Output layer for 6-class classification
    keras.layers.Dense(6, activation='softmax')
])

# Compile the model
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=1e-4),
    loss=sparse_categorical_focal_loss(alpha=0.25, gamma=2.0),
    metrics=['accuracy']
)

# Display model architecture summary
model.summary()

"""## Model Training Procedure
The model is trained using supervised learning with early stopping to prevent overfitting.

### Training Details
- **Batch size:** 32
- **Maximum epochs:** 50
- **Optimizer:** Adam
- **Learning rate:** 1e-4
- **Validation strategy:** Hold-out validation set

"""

from tensorflow.keras.callbacks import EarlyStopping

# Early stopping callback to prevent overfitting
early_stop = EarlyStopping(
    monitor='val_loss',         # Track validation loss
    patience=7,                 # Stop if no improvement for 7 epochs
    restore_best_weights=True   # Revert to best model weights
)

# Train the model
history = model.fit(
    # Forward pass: images → predictions
    X_train_np, y_train_np,
    batch_size=32,
    epochs=50,

    # Validation used to monitor generalization
    validation_data=(X_val_np, y_val_np),
    # Backpropagation + optimizer updates handled internally
    callbacks=[early_stop]
)

"""### Deep Learning Training Flow Explanation

1. **Forward Pass**
   - Input images are passed through EfficientNet and classification layers
   - Softmax outputs class probabilities

2. **Loss Computation**
   - Sparse Categorical Focal Loss computes error per sample

3. **Backpropagation**
   - Gradients of the loss are calculated w.r.t. trainable weights

4. **Optimizer Update**
   - Adam optimizer updates weights using computed gradients

This process repeats for each batch and epoch.

"""

# Evaluate trained model on unseen test data

loss, accuracy = model.evaluate(X_test_np, y_test_np)
print(f'Model Accuracy : {accuracy * 100}')

# Generate class probability predictions
pred = np.argmax(model.predict(X_test_np), axis=-1)

"""## Model Evaluation and Performance Analysis
This section evaluates the trained model using multiple quantitative metrics and visual diagnostics.
Given the clinical nature of the task and class imbalance, performance is assessed beyond accuracy,
using macro-averaged metrics and class-wise error analysis.

"""

# Import confusion matrix for classification error analysis
from sklearn.metrics import confusion_matrix
# Seaborn is used for visually enhanced heatmaps
import seaborn as sns

# Compute normalized confusion matrix
# normalize='true' ensures values are shown as per-class proportions
cf = confusion_matrix(y_test_np, pred, normalize = 'true')
sns.heatmap(cf, annot = True, cmap = 'Blues');
plt.xlabel('Predicted Class')
plt.ylabel('Actual Class')
plt.title('Confusion Matrix')

"""### Confusion Matrix Interpretation

The normalized confusion matrix highlights class-wise prediction behavior.
This analysis is critical for identifying:
- Misclassification between morphologically similar tissue types
- Bias toward majority classes
- Performance degradation on rare classes such as Serrated Adenoma

Normalization ensures fair comparison across imbalanced classes.

"""

import matplotlib.pyplot as plt

# Plot training and validation loss over epochs
plt.figure(figsize=(8, 5))
# Training loss curve
plt.plot(history.history['loss'], label='Training Loss')
# Validation loss curve
plt.plot(history.history['val_loss'], label='Validation Loss')

plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training vs Validation Loss')
plt.legend()
plt.grid(True)
plt.show()

"""### Loss Curve Analysis

The loss curves are used to monitor convergence and detect overfitting.
Early stopping was applied once validation loss stopped improving,
ensuring that the model did not overfit augmented training data.

"""

# Plot training and validation accuracy over epochs
plt.figure(figsize=(8, 5))
# Training accuracy curve
plt.plot(history.history['accuracy'], label='Training Accuracy')
# Validation accuracy curve
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')

plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training vs Validation Accuracy')
plt.legend()
plt.grid(True)
plt.show()

"""### Accuracy Curve Analysis

Accuracy trends provide insight into learning stability.
However, due to class imbalance, accuracy alone is not sufficient
and is complemented with macro-averaged metrics.

"""

from sklearn.metrics import f1_score

# Compute macro-averaged F1-score
# Macro F1 gives equal importance to all classes
macro_f1 = f1_score(y_test, pred, average='macro')

print(f"Primary Metric (Macro F1-score): {macro_f1:.4f}")

"""### Primary Performance Metric: Macro F1-Score

Macro F1-score is selected as the primary metric because:
- It treats all classes equally
- It is robust to class imbalance
- It reflects performance on rare pathological classes

This metric is more clinically meaningful than accuracy alone.

"""

from sklearn.metrics import accuracy_score

# Compute overall accuracy
accuracy = accuracy_score(y_test, pred)

print(f"Accuracy: {accuracy:.4f}")

import numpy as np
import matplotlib.pyplot as plt

# Convert multiclass labels into binary format
from sklearn.preprocessing import label_binarize

# Import ROC and AUC computation utilities
from sklearn.metrics import roc_curve, auc

"""## ROC Curve and AUC Analysis (Multi-Class)

"""

# Class labels in the same order as encoding
CATEGORIES = [
    'Adenocarcinoma',
    'High-grade IN',
    'Low-grade IN',
    'Normal',
    'Polyp',
    'Serrated adenoma'
]

n_classes = len(CATEGORIES)

# Predict class probabilities for the test set
y_score = model.predict(X_test_np)   # shape: (samples, 6)

# Convert true test labels into one-hot encoded format
y_test_bin = label_binarize(y_test, classes=list(range(n_classes)))

# Dictionaries to store ROC values for each class
fpr = {}    # False Positive Rate
tpr = {}    # True Positive Rate
roc_auc = {}

# Compute ROC curve and AUC for each class
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Aggregate all false positive rates
all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))

# Interpolate true positive rates for macro-average ROC
mean_tpr = np.zeros_like(all_fpr)
for i in range(n_classes):
    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])

# Compute average across all classes
mean_tpr /= n_classes

# Compute macro-average AUC
macro_auc = auc(all_fpr, mean_tpr)

plt.figure(figsize=(8, 6))

# Plot ROC for each class
for i in range(n_classes):
    plt.plot(
        fpr[i],
        tpr[i],
        label=f"{CATEGORIES[i]} (AUC = {roc_auc[i]:.2f})"
    )

# Plot macro-average ROC
plt.plot(
    all_fpr,
    mean_tpr,
    linestyle='--',
    linewidth=3,
    label=f"Macro-average (AUC = {macro_auc:.2f})"
)

# Plot diagonal for random classifier
plt.plot([0, 1], [0, 1], 'k--')

plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve – 6-Class Colon Cancer Classification')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()

"""### ROC and AUC Interpretation

ROC curves illustrate the trade-off between sensitivity and specificity
for each class in a one-vs-rest setting.

The macro-average AUC provides a balanced view of overall discrimination
performance across all six tissue classes, including rare lesions.

## Detailed Class-wise Performance Report
To provide a transparent and clinically meaningful evaluation, we report
class-wise precision, recall, and F1-score for each colorectal tissue category.

This analysis is particularly important due to:
- Severe class imbalance in the dataset
- Morphological similarity between certain classes
- Clinical importance of correctly identifying rare and high-risk lesions
"""

# Import detailed classification metrics
from sklearn.metrics import classification_report, precision_score, recall_score, f1_score

# Generate a detailed per-class performance report
# Includes precision, recall, F1-score, and support for each class
print(classification_report(
    y_test_np,
    pred,
    target_names=[
        'Adenocarcinoma',
        'High-grade IN',
        'Low-grade IN',
        'Normal',
        'Polyp',
        'Serrated adenoma'
    ],
    digits=4  # Display metrics with high numerical precision
))

"""### Interpretation of the Classification Report
The classification report provides class-wise insight into model behavior:

- **Precision** reflects how many predicted samples of a class are truly correct,
  which is important to avoid false positive diagnoses.
- **Recall (Sensitivity)** indicates the model’s ability to detect all true cases,
  which is critical in medical screening tasks.
- **F1-score** balances precision and recall, making it suitable for imbalanced datasets.

Lower scores in rare classes such as *Serrated Adenoma* are expected due to limited
training samples and high morphological variability. This limitation was mitigated
through class-aware augmentation and macro-averaged evaluation metrics.

"""

#model.save("efficientnet_colon_cancer_model.h5")